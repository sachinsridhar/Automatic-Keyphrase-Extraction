{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import and Parse the .json files into the python environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has the json library which enables us to parse the dataset. We observe that the Json files are similar to a Python dictionary, and comprises Strings, Numbers, Lists and Nested Lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of the dataset\n",
    "\n",
    "The dataset contains all details corresponding to 469 e-mails from an inbox. This is a list of dictionaries - where each dictionary corresponds to one email, and each of the keys (of a particular dictionary) corresponds to a specific piece of information regarding the mail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To import the file in this manner, ensure that the data is in the same folder as that of the jupyter(.ipynb) notebook\n",
    "sourceFile = open(\"anupriya@moduleq.com.emails.txt\") # One of the 4 files\n",
    "json_data = json.load(sourceFile)\n",
    "\n",
    "# This file test2.txt contains one of the files with the all the mails from a particular inbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469\n"
     ]
    }
   ],
   "source": [
    "print(len(json_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 469 mails in this dataframe.\n",
    "\n",
    "**In order to study the structure of each dictionary in this list, let us look at each of the keys.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['@odata.etag', 'id', 'createdDateTime', 'lastModifiedDateTime', 'changeKey', 'categories', 'receivedDateTime', 'sentDateTime', 'hasAttachments', 'internetMessageId', 'subject', 'bodyPreview', 'importance', 'parentFolderId', 'conversationId', 'isDeliveryReceiptRequested', 'isReadReceiptRequested', 'isRead', 'isDraft', 'webLink', 'inferenceClassification', 'body', 'sender', 'from', 'toRecipients', 'ccRecipients', 'bccRecipients', 'replyTo'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data[1].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on the set of keys printed above, we observe that from an Automatic Keyphrase Extraction perspective, many of the keys (details of the mail) are not relevant and can be excluded from further processing steps.**\n",
    "\n",
    "Let us therefore convert this list of dictionaries to a pandas dataframe and then exclude the non-relevant information (columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "email_dataframe = pd.DataFrame(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(469, 28)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_dataframe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the 28 columns, we only retain the subject line ('subject') and the content of the mail ('body'), excluding information such as send date, time, has Attachment?, importance, and so on ... Since they do not enable Automatic Keyphrase Extractions in any way, we exclude them from the dataframe and retain only these two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['@odata.etag', 'bccRecipients', 'body', 'bodyPreview',\n",
       "       'categories', 'ccRecipients', 'changeKey', 'conversationId',\n",
       "       'createdDateTime', 'from', 'hasAttachments', 'id', 'importance',\n",
       "       'inferenceClassification', 'internetMessageId',\n",
       "       'isDeliveryReceiptRequested', 'isDraft', 'isRead',\n",
       "       'isReadReceiptRequested', 'lastModifiedDateTime', 'parentFolderId',\n",
       "       'receivedDateTime', 'replyTo', 'sender', 'sentDateTime', 'subject',\n",
       "       'toRecipients', 'webLink'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_dataframe.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'contentType': 'html', 'content': '&lt;html&gt;\r\n",
       "&lt;h...</td>\n",
       "      <td>[JIRA] (MQ-482) Email fetch not working locally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'contentType': 'html', 'content': '&lt;html&gt;\r\n",
       "&lt;h...</td>\n",
       "      <td>[JIRA] (MQ-525) Improve monitoring capability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'contentType': 'html', 'content': '&lt;html&gt;\r\n",
       "&lt;h...</td>\n",
       "      <td>[JIRA] (MQ-525) Improve monitoring capability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'contentType': 'html', 'content': '&lt;html&gt;\r\n",
       "&lt;h...</td>\n",
       "      <td>[JIRA] (MQ-539) Capture and log user input to Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'contentType': 'html', 'content': '&lt;html&gt;\r\n",
       "&lt;h...</td>\n",
       "      <td>[Confluence] MQ.ai &gt; 2017-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'contentType': 'html', 'content': '&lt;html&gt;\r\n",
       "&lt;h...</td>\n",
       "      <td>Re: [moduleQ/MQ.ai] Changed 'Create priority' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'contentType': 'html', 'content': '&lt;html&gt;\r\n",
       "&lt;h...</td>\n",
       "      <td>Re: [moduleQ/MQ.ai] Fixed truncation for morni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'contentType': 'html', 'content': '&lt;html&gt;\r\n",
       "&lt;h...</td>\n",
       "      <td>Re: [moduleQ/MQ.ai] MQ-527 duplicate key value...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'contentType': 'html', 'content': '&lt;html&gt;\r\n",
       "&lt;h...</td>\n",
       "      <td>[moduleQ/MQ.ai] Feature/mq 554 own service url...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'contentType': 'html', 'content': '&lt;html&gt;\r\n",
       "&lt;h...</td>\n",
       "      <td>[JIRA] (MQ-539) Capture and log user input to Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'contentType': 'html', 'content': '&lt;html&gt;\r\n",
       "&lt;h...</td>\n",
       "      <td>[JIRA] (MQ-539) Capture and log user input to Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'contentType': 'html', 'content': '&lt;html&gt;\r\n",
       "&lt;h...</td>\n",
       "      <td>[JIRA] (MQ-482) Email fetch not working locally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'contentType': 'html', 'content': '&lt;html&gt;\r\n",
       "&lt;h...</td>\n",
       "      <td>Re: [moduleQ/MQ.ai] Feature/mq 554 own service...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'contentType': 'html', 'content': '&lt;html&gt;\r\n",
       "&lt;h...</td>\n",
       "      <td>Morning Briefing questions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'contentType': 'html', 'content': '&lt;html&gt;\r\n",
       "&lt;h...</td>\n",
       "      <td>[JIRA] (MQ-539) Capture and log user input to Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 body  \\\n",
       "0   {'contentType': 'html', 'content': '<html>\n",
       "<h...   \n",
       "1   {'contentType': 'html', 'content': '<html>\n",
       "<h...   \n",
       "2   {'contentType': 'html', 'content': '<html>\n",
       "<h...   \n",
       "3   {'contentType': 'html', 'content': '<html>\n",
       "<h...   \n",
       "4   {'contentType': 'html', 'content': '<html>\n",
       "<h...   \n",
       "5   {'contentType': 'html', 'content': '<html>\n",
       "<h...   \n",
       "6   {'contentType': 'html', 'content': '<html>\n",
       "<h...   \n",
       "7   {'contentType': 'html', 'content': '<html>\n",
       "<h...   \n",
       "8   {'contentType': 'html', 'content': '<html>\n",
       "<h...   \n",
       "9   {'contentType': 'html', 'content': '<html>\n",
       "<h...   \n",
       "10  {'contentType': 'html', 'content': '<html>\n",
       "<h...   \n",
       "11  {'contentType': 'html', 'content': '<html>\n",
       "<h...   \n",
       "12  {'contentType': 'html', 'content': '<html>\n",
       "<h...   \n",
       "13  {'contentType': 'html', 'content': '<html>\n",
       "<h...   \n",
       "14  {'contentType': 'html', 'content': '<html>\n",
       "<h...   \n",
       "\n",
       "                                              subject  \n",
       "0     [JIRA] (MQ-482) Email fetch not working locally  \n",
       "1       [JIRA] (MQ-525) Improve monitoring capability  \n",
       "2       [JIRA] (MQ-525) Improve monitoring capability  \n",
       "3     [JIRA] (MQ-539) Capture and log user input to Q  \n",
       "4                     [Confluence] MQ.ai > 2017-03-15  \n",
       "5   Re: [moduleQ/MQ.ai] Changed 'Create priority' ...  \n",
       "6   Re: [moduleQ/MQ.ai] Fixed truncation for morni...  \n",
       "7   Re: [moduleQ/MQ.ai] MQ-527 duplicate key value...  \n",
       "8   [moduleQ/MQ.ai] Feature/mq 554 own service url...  \n",
       "9     [JIRA] (MQ-539) Capture and log user input to Q  \n",
       "10    [JIRA] (MQ-539) Capture and log user input to Q  \n",
       "11    [JIRA] (MQ-482) Email fetch not working locally  \n",
       "12  Re: [moduleQ/MQ.ai] Feature/mq 554 own service...  \n",
       "13                         Morning Briefing questions  \n",
       "14    [JIRA] (MQ-539) Capture and log user input to Q  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Considering only the reduced dataframe with only the required columns - \n",
    "reduced_dataframe = email_dataframe[['body','subject']]\n",
    "reduced_dataframe.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on the dataframe, we observe that the entry in the column 'body' is by itself a dictionary, with two keys. The first key 'contentType' can be excluded, as it redundantly states that the content type is html. The second key 'content' is what we need to focus on.**\n",
    "\n",
    "**The second column of the dataframe is the subject of the mail, from which parts of text such as \"JIRA(MQ-XXX)\" and \"Re:(moduleQ/MQ.ai)\" are to be excluded.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a trial operation, let us work on the content of just the first row (first mail) in the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': '<html>\\r\\n<head>\\r\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\\r\\n<meta content=\"text/html; charset=utf-8\">\\r\\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, maximum-scale=1.0\">\\r\\n<base href=\"https://moduleq.atlassian.net\">\\r\\n</head>\\r\\n<body class=\"jira\" style=\"color:#333333; font-family:Arial,sans-serif; font-size:14px; line-height:1.429\">\\r\\n<table id=\"background-table\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\" bgcolor=\"#f5f5f5\" style=\"border-collapse:collapse; background-color:#f5f5f5; border-collapse:collapse\">\\r\\n<tbody>\\r\\n<tr>\\r\\n<td id=\"header-pattern-container\" style=\"padding:0; border-collapse:collapse; padding:10px 20px\">\\r\\n<table id=\"header-pattern\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\" style=\"border-collapse:collapse\">\\r\\n<tbody>\\r\\n<tr>\\r\\n<td id=\"header-avatar-image-container\" valign=\"top\" width=\"32\" style=\"padding:0; border-collapse:collapse; vertical-align:top; width:32px; padding-right:8px\">\\r\\n<img id=\"header-avatar-image\" class=\"image_fix\" src=\"cid:jira-generated-image-avatar-80caa057-7117-4a0d-bf6b-6ec1cad4237f\" height=\"32\" width=\"32\" border=\"0\" style=\"border-radius:3px; vertical-align:top\">\\r\\n</td>\\r\\n<td id=\"header-text-container\" valign=\"middle\" style=\"padding:0; border-collapse:collapse; vertical-align:middle; font-family:Arial,sans-serif; font-size:14px; line-height:20px\">\\r\\n<a class=\"user-hover\" rel=\"vrubinskyi\" id=\"email_vrubinskyi\" href=\"https://moduleq.atlassian.net/secure/ViewProfile.jspa?name=vrubinskyi\" style=\"color:#3b73af; color:#3b73af; text-decoration:none\">Vasyl Rubinskyi</a>\\r\\n<strong>commented</strong> on <a href=\"https://moduleq.atlassian.net/browse/MQ-482\" style=\"color:#3b73af; text-decoration:none\">\\r\\n<img src=\"cid:jira-generated-image-avatar-2017b0bd-0564-481a-9f46-616194c2ddb2\" height=\"16\" width=\"16\" border=\"0\" align=\"absmiddle\" alt=\"Bug\"> MQ-482</a>\\r\\n</td>\\r\\n</tr>\\r\\n</tbody>\\r\\n</table>\\r\\n</td>\\r\\n</tr>\\r\\n<tr>\\r\\n<td id=\"email-content-container\" style=\"padding:0; border-collapse:collapse; padding:0 20px\">\\r\\n<table id=\"email-content-table\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"border-collapse:collapse; border-spacing:0; border-collapse:separate\">\\r\\n<tbody>\\r\\n<tr>\\r\\n<td class=\"email-content-rounded-top mobile-expand\" height=\"10\" bgcolor=\"#ffffff\" style=\"padding:0; border-collapse:collapse; color:#ffffff; padding:0 15px 0 16px; height:15px; background-color:#ffffff; border-left:1px solid #cccccc; border-top:1px solid #cccccc; border-right:1px solid #cccccc; border-bottom:0; border-top-right-radius:5px; border-top-left-radius:5px; height:10px; line-height:10px; padding:0 15px 0 16px\">\\r\\n&nbsp;</td>\\r\\n</tr>\\r\\n<tr>\\r\\n<td class=\"email-content-main mobile-expand \" bgcolor=\"#ffffff\" style=\"padding:0; border-collapse:collapse; border-left:1px solid #cccccc; border-right:1px solid #cccccc; border-top:0; border-bottom:0; padding:0 15px 0 16px; background-color:#ffffff\">\\r\\n<table class=\"page-title-pattern\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"border-collapse:collapse\">\\r\\n<tbody>\\r\\n<tr>\\r\\n<td class=\"page-title-pattern-header-container\" style=\"vertical-align:top; padding:0; border-collapse:collapse; padding-right:5px; font-size:20px; line-height:30px\">\\r\\n<span class=\"page-title-pattern-header\" style=\"font-family:Arial,sans-serif; padding:0; font-size:20px; line-height:30px; vertical-align:middle\"><a href=\"https://moduleq.atlassian.net/browse/MQ-482\" style=\"color:#3b73af; text-decoration:none\">Re: Email fetch\\r\\n not working locally</a> </span></td>\\r\\n</tr>\\r\\n</tbody>\\r\\n</table>\\r\\n</td>\\r\\n</tr>\\r\\n<tr>\\r\\n<td id=\"text-paragraph-pattern-top\" class=\"email-content-main mobile-expand  comment-top-pattern\" bgcolor=\"#ffffff\" style=\"padding:0; border-collapse:collapse; border-left:1px solid #cccccc; border-right:1px solid #cccccc; border-top:0; border-bottom:0; padding:0 15px 0 16px; background-color:#ffffff; border-bottom:none; padding-bottom:0\">\\r\\n<table class=\"text-paragraph-pattern\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"border-collapse:collapse; font-family:Arial,sans-serif; font-size:14px; line-height:20px\">\\r\\n<tbody>\\r\\n<tr>\\r\\n<td class=\"text-paragraph-pattern-container mobile-resize-text \" style=\"padding:0; border-collapse:collapse; padding:0 0 10px\">\\r\\n<p style=\"margin:10px 0 0; margin-top:0\"><a href=\"https://moduleq.atlassian.net/secure/ViewProfile.jspa?name=ryan\" class=\"user-hover\" rel=\"ryan\" style=\"color:#3b73af; text-decoration:none\">Ryan Curd</a> Seems to be fixed. I guess it may be closed.\\r\\n</p>\\r\\n</td>\\r\\n</tr>\\r\\n</tbody>\\r\\n</table>\\r\\n</td>\\r\\n</tr>\\r\\n<tr>\\r\\n<td class=\"email-content-main mobile-expand \" bgcolor=\"#ffffff\" style=\"padding:0; border-collapse:collapse; border-left:1px solid #cccccc; border-right:1px solid #cccccc; border-top:0; border-bottom:0; padding:0 15px 0 16px; background-color:#ffffff\">\\r\\n<table id=\"actions-pattern\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"100%\" style=\"border-collapse:collapse; font-family:Arial,sans-serif; font-size:14px; line-height:20px\">\\r\\n<tbody>\\r\\n<tr>\\r\\n<td id=\"actions-pattern-container\" valign=\"middle\" style=\"padding:0; border-collapse:collapse; padding:10px 0 10px 24px; vertical-align:middle; padding-left:0\">\\r\\n<table align=\"left\" style=\"border-collapse:collapse\">\\r\\n<tbody>\\r\\n<tr>\\r\\n<td class=\"actions-pattern-action-icon-container\" style=\"padding:0; border-collapse:collapse; font-family:Arial,sans-serif; font-size:14px; line-height:20px; vertical-align:middle\">\\r\\n<a href=\"https://moduleq.atlassian.net/browse/MQ-482#add-comment\" target=\"_blank\" title=\"Add Comment\" style=\"color:#3b73af; text-decoration:none\"><img class=\"actions-pattern-action-icon-image\" src=\"cid:jira-generated-image-static-comment-icon-4c2b26ca-63d8-44ff-b382-9dcf4c10867b\" alt=\"Add Comment\" title=\"Add Comment\" height=\"16\" width=\"16\" border=\"0\" style=\"vertical-align:middle\">\\r\\n</a></td>\\r\\n<td class=\"actions-pattern-action-text-container\" style=\"padding:0; border-collapse:collapse; font-family:Arial,sans-serif; font-size:14px; line-height:20px; padding-left:5px\">\\r\\n<a href=\"https://moduleq.atlassian.net/browse/MQ-482#add-comment\" target=\"_blank\" title=\"Add Comment\" style=\"color:#3b73af; text-decoration:none\">Add Comment</a>\\r\\n</td>\\r\\n</tr>\\r\\n</tbody>\\r\\n</table>\\r\\n</td>\\r\\n</tr>\\r\\n</tbody>\\r\\n</table>\\r\\n</td>\\r\\n</tr>\\r\\n<tr>\\r\\n<td class=\"email-content-rounded-bottom mobile-expand\" height=\"5\" bgcolor=\"#ffffff\" style=\"padding:0; border-collapse:collapse; color:#ffffff; padding:0 15px 0 16px; height:5px; line-height:5px; background-color:#ffffff; border-top:0; border-left:1px solid #cccccc; border-bottom:1px solid #cccccc; border-right:1px solid #cccccc; border-bottom-right-radius:5px; border-bottom-left-radius:5px\">\\r\\n&nbsp;</td>\\r\\n</tr>\\r\\n</tbody>\\r\\n</table>\\r\\n</td>\\r\\n</tr>\\r\\n<tr>\\r\\n<td id=\"footer-pattern\" style=\"padding:0; border-collapse:collapse; padding:12px 20px\">\\r\\n<table id=\"footer-pattern-container\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\" style=\"border-collapse:collapse\">\\r\\n<tbody>\\r\\n<tr>\\r\\n<td id=\"footer-pattern-text\" class=\"mobile-resize-text\" width=\"100%\" style=\"padding:0; border-collapse:collapse; color:#999999; font-size:12px; line-height:18px; font-family:Arial,sans-serif\">\\r\\nThis message was sent by Atlassian JIRA <span id=\"footer-build-information\">(v1000.824.2#100035-<span title=\"a97671d0d959bbcc2acfe5d2c75ef6605a61c8c1\">sha1:a97671d</span>)</span>\\r\\n</td>\\r\\n<td id=\"footer-pattern-logo-desktop-container\" valign=\"top\" style=\"padding:0; border-collapse:collapse; padding-left:20px; vertical-align:top\">\\r\\n<table style=\"border-collapse:collapse\">\\r\\n<tbody>\\r\\n<tr>\\r\\n<td id=\"footer-pattern-logo-desktop-padding\" style=\"padding:0; border-collapse:collapse; padding-top:3px\">\\r\\n<img id=\"footer-pattern-logo-desktop\" src=\"cid:jira-generated-image-static-footer-desktop-logo-c42ff485-ed2c-41a3-b51d-989bb5bd074f\" alt=\"Atlassian logo\" title=\"Atlassian logo\" width=\"169\" height=\"36\" class=\"image_fix\">\\r\\n</td>\\r\\n</tr>\\r\\n</tbody>\\r\\n</table>\\r\\n</td>\\r\\n</tr>\\r\\n</tbody>\\r\\n</table>\\r\\n</td>\\r\\n</tr>\\r\\n</tbody>\\r\\n</table>\\r\\n</body>\\r\\n</html>\\r\\n',\n",
       " 'contentType': 'html'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_dataframe['body'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = email_dataframe['body'][0]\n",
    "\n",
    "keys = list(dictionary.keys())\n",
    "values = list(dictionary.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values[0] contains the first value, corresponding to the key-value pair {contentType': 'html'}\n",
    "# values[1] contains the text to be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = dictionary.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys, values = zip(*dictionary.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nVasyl Rubinskyi\\ncommented on \\n MQ-482\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n\\xa0\\n\\n\\n\\n\\n\\n\\n\\nRe: Email fetch\\r\\n not working locally \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRyan Curd Seems to be fixed. I guess it may be closed.\\r\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAdd Comment\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n\\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\nThis message was sent by Atlassian JIRA (v1000.824.2#100035-sha1:a97671d)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us use beautiful soup to parse this html content\n",
    "htmltext = values[1]\n",
    "soup = BeautifulSoup(htmltext, 'lxml')\n",
    "cleaned_text = soup.text\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that all the html content has been removed from the text, but some other \"\\n\", \"\\r\" type of tags remain. Let us exclude them using the text.replace() command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = cleaned_text.replace('\\n','')\n",
    "cleaned_text = cleaned_text.replace('\\r','')\n",
    "cleaned_text = cleaned_text.replace('\\xa0',' ')\n",
    "cleaned_text = cleaned_text.replace('Add Comment This message was sent by Atlassian JIRA (v1000.824.2#100035-sha1:a97671d)','')\n",
    "cleaned_text = re.sub('<.*?>', '', cleaned_text)\n",
    "cleaned_text = re.sub('Add Comment.*?a97671d\\)','',cleaned_text)\n",
    "cleaned_text = re.sub('Sherry.*?artificial intelligence. ','',cleaned_text)\n",
    "cleaned_text = re.sub('Margo Poda.*?@ModuleQ ','',cleaned_text)\n",
    "cleaned_text = re.sub('Sent from my iPhone.*?[A-Za-z]+','',cleaned_text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vasyl Rubinskyicommented on  MQ-482 Re: Email fetch not working locally Ryan Curd Seems to be fixed. I guess it may be closed.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The above operation shows that we can use the Beautiful Soup library to clean the *content* of the mail. Let us now operationalize these steps for all 469 mails using a for loop.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_cleaned_mails = []\n",
    "for i in range(0,len(json_data)):\n",
    "    dictionary1 = email_dataframe['body'][i]\n",
    "    keys1 = list(dictionary1.keys())\n",
    "    values1 = list(dictionary1.values())\n",
    "    htmltext1 = values1[1]\n",
    "    soup = BeautifulSoup(htmltext1, 'lxml')\n",
    "    cleaned_text = soup.text\n",
    "    cleaned_text = cleaned_text.replace('\\n','')\n",
    "    cleaned_text = cleaned_text.replace('\\r','')\n",
    "    cleaned_text = cleaned_text.replace('\\t','')\n",
    "    cleaned_text = cleaned_text.replace('\\xa0',' ')\n",
    "    cleaned_text = cleaned_text.replace('Reply to this email directly, view it on GitHub, or mute the thread.','')\n",
    "    cleaned_text = re.sub('<.*?>', '', cleaned_text)\n",
    "    cleaned_text = re.sub('Add Comment.*?a97671d\\)','',cleaned_text)\n",
    "    cleaned_text = re.sub('Sherry.*?artificial intelligence. ','',cleaned_text) # Not exhaustive or appropriate\n",
    "    cleaned_text = re.sub('Margo Poda.*?@ModuleQ ','',cleaned_text)\n",
    "    cleaned_text = re.sub('Sent from my iPhone.*?[A-Za-z]+','',cleaned_text)\n",
    "    \n",
    "    list_of_cleaned_mails.append(cleaned_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include this list as an additional column in the pandas dataframe\n",
    "reduced_dataframe['cleaned_content'] = list_of_cleaned_mails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_cleaned_mails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us view some sample entries of the column: cleaned_content to get a sense of the type of communication\n",
    "list_of_cleaned_mails[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the subject lines:\n",
    "list_of_subjects = list(reduced_dataframe['subject'][0:30])\n",
    "list_of_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dataframe['cleaned_content'][0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on the basic cleaning operations carried out on the mails in the previous notebook, a set of 16 mails have been selected for analysis.**\n",
    "\n",
    "Note to self: I had to perform some cleaning steps manually at the end to get the mail content in its cleanest form. This was just a trial exercise - In the future, target automating these cleaning operations using code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_mail_text = [\"Anupriya, I just had some questions about information in the morning briefing. For reference here is mine for today with numbers that correspond to my questions. On the main priority listing card, Do the numbers represent the importance of the priority, its ranking? If so, it seems to me like Microsoft should be in the number one priority based on more emails and a more recent upward trend. Do the priorities reorder themselves based on trends?Also the text below (which is unfortunately cut off here) says 'green arrows' and should probably read 'green numbers'. On the individual priority card, there are two numbers under activity (42 emails and 57 total). The total number here does not match the email number from the first card. I assume this is a bug. What is the scope of the first number that it is less than the total? Is it the past week only? It might be good to put a qualifier in there to help not confuse people. I assume the gray band is the next upcoming meeting in that priority. Again, we might want to consider noting that so people know what it's telling them. The date and time are wrong. It appears to only display the current date and time in GMT. I assume this is another bug.a. I assume I have two entries under one email because it was somehow split, correct? I can’t seem to find an email between just me and Vasyl on for this thread though.b. Similar to new priority notifications, should my name be appearing here or should it be omitted. I know it's a lot of questions, so thanks in advance for your patience. Ryan\",\n",
    "\n",
    " \"Nikolay Borovenskiy commented on  MQ-539 Re: Capture and log user input to Q. It is fine for me use database, you have my voice to follow this approach. I hope that very soon we will have an admin panel and will be able to display this information very friendly. But I must know which one approach to do. So I am waiting your decision.\",\n",
    "\n",
    " \"Session decrease today – and that is to be expected (so far, it's early, but I'll be gone tonight so I'll check in tomorrow).\",\n",
    "\n",
    " \"Monthly product updates, pro-tips, and events from the Sentry team. Product updates for March 2017 Happy March! We'll try not to be too offended if you want to unsubscribe from our monthly product updates. Feel free to remove yourself by clicking the link in the email footer. Here are some updates we've recently shipped at Sentry. Product updates iOS Reprocessing Have you ever been in a situation where your app crashes before you've uploaded your debug symbols to us? Well, we're happy to say Sentry has gotten a whole lot better here. You can now enable a feature we call reprocessing (in your project settings), which will delay parsing your errors until you've uploaded the relevant symbols. —Armin Learn more More iOS updates Okay Armin, we get it, reprocessing will make debugging easier. But only because of the big update we made to our Swift SDK. Make sure you check out ourdocs and update Swift. —DanielBilling Update We changed our pricing model in January for all new Sentry users. If you’re currently on a paid legacy plan, hold tight! You'll hear from us in the coming months about the migration process to the new plan.—Jess A. Psst...We have a cool new update coming to releases. Stay tuned! —Jess M. Inside Sentry updatesDodging S3 Downtime with Nginx and HAProxy How we reduced our S3 bandwidth costs by 70% while gaining more performance and reliability. - Matt Learn more ICYMI Error handling in Node. jsI gave a talk in the March SFNode meetup at our office. You can check out the recording of this talkhere or just go through the slides to learn more. — Lewis Filtering exceptions Olark, one of our exceptional customers, wrote this great blog post on how they get the most out of Sentry. If you have your own way of filtering and want to share, send us a quick email. Pro-Tips Be sure to update your Javascript SDKWe updated our browser JavaScript SDK to prevent sending the same event back-to-back. We've also made other fixes to surface higher quality errors in some situations.\",\n",
    "\n",
    " \"Nikolay Borovenskiy commented on  MQ-539 Re: Capture and log user input to Q Anupriya Ankolekar Yes, they will. We'll do foreign key for each user. We need to think about how to show this information. I hold in my head only admin panel as instrument to show it. or use tools to get access to data base. These are mostly facts we know but backed up here. It is good coverage of MSFT Teams.\",\n",
    "\n",
    " \"It is a useful number. Some people that we have spoken to get more then 300 a day. Those were typically consulting or sales managers. Of course many of those were internal emails because they worked in large organizations. By this article internal email volume decreased also. Teams makes that happen. We improve the experience in Teams with external emails by surfacing priority communications.\",\n",
    "\n",
    " \"My experience. I had to delete Steve Vigo as I noticed he got in the way. MSFT needs to sort that out. Once I signed into Teams and engaged it did the binding which just spun. I watched it for a bit then I looked at Teams and it in fact was working fine. So it did work but as a user, I thought it did not ... initially. Another point on the priority identification. I got 3 recommended in this order - EY – I accepted Royal Coffee – I accepted but I don’t understand why it came up. I have no meeting set up with them at all. Pressly – I did have one meeting set up and a few emails. It did not recommend Microsoft in the first 3 which is most alarming. I have meetings set up in the near past and future and lots of emails with them. It is most of my email traffic.\",\n",
    "\n",
    " \"Steve was not showing up when I logged in. The priorities were not right. Even though I accepted Royal Cup Coffee it did not fit a priority as I thought we had defined it. I have no meeting set up with them and I haven't had a meeting for maybe 4 months … or more.  Microsoft should have been right below EY or ahead of EY and it didn't show up in the first 3. Pressly was one meeting and not more then 3 emails. Those 3 emails are in one chain. There is only one person on the Pressly email and meeting. There are many people on the EY and MSFT meetings and emails. So it seems a little random to me.\",\n",
    "\n",
    " \"Interesting! ... Now I do remember your mentioning this number before for consulting and sales managers. The magnitude of that wrt how Q will perform is now starting to sink in for me. Something to keep in mind as we go through the next iteration of Q's design. You're right that if a target organization is already using Teams, then when they start using Q, the email traffic should be smaller. I'm mostly thinking about the initial experience, if they are new to both Q and Teams when we start working with them. Once they have put up with us for a while, they are more likely to stay.And hopefully not all of the 300 emails were priority communications, so our notifications will definitely present a smaller set. Still, we may ultimately need to become clever about which kinds of notifications we show even for accepted priorities or allow users to set manual filters if they want to.\",\n",
    "\n",
    " \"Okay, it sounds like the ranking is really off for you. I am working on coming up with changes to the clustering algorithm first and then for the ranking of these priorities. David and I were thinking of a rule-based approach to the initial clustering and ranking. I'm making a list of rules to apply and will get back to you for verification/validation of these. In the meantime, feel free to tell me anything else you find odd. I want to address as many issues as possible.\",\n",
    "\n",
    " 'Thanks Margo for keeping us updated. We have a few random new users, so some are enticed enough to add our bot. :) Hope you are having fun!',\n",
    "\n",
    " \"Hi Ryan, No worries about the length, only got to it a bit later, cause I wanted to answer properly. :) 1. Yes, the order should correspond to their importance. The priorities currently do not reorder themselves, so they are in undefined order. Once the priority dashboard is in place, people will be able to reorder priorities and then this ranking should correspond to their user-defined ranking.a. It is indeed wrong and should say 'marked in green', but the developers missed that new text I think. It is a simple fix in MQ.ai/moduleq/bot/views/templates/bulletin/summary.xml, so I will do it (has been on my todo list for a while.)2. Yes and yes. Those numbers have been an issue. It should say 42 emails this week and 57 emails in total. That was specified originally, but got lost. The number 57 should appear in the summary view too. This is definitely a problem. The numbers are calculated differently: for the summary, it is read from the json query (I have to check how that is calculated), for the detail view, it is a sum of the numbers used to generate the activity graph. So, I guess they will always be close, but they really should be the same.3. Yes, the upcoming meeting might be more obvious with a clear line saying 'Upcoming meeting'. I hadn\\'t noticed the date and time problems. They are definitely wrong and not having timezone there is an issue!4. Just looks like a bug to me. Email addressees are not supposed to be split over two lines. I don\\'t see why that should happen.5. Although this is a different case than new priority notifications, omitting the user\\'s name (which will always be present) saves space, so I suggest removing it here as well. That said, for new email notifications which contain a snippet of the new email, it made sense to keep the user in there, because there we\\'re presenting the email there as a purer object, which has the user as an attribute as well. That said, this is fuzzy reasoning, so I can be persuaded either way.Btw, I can work on 1a, 2a, 3 and 4 (you won\\'t need to create separate JIRA items for each of them). Just let me know.Also, as a heads up, although not a prerequisite here, it would help immensely for design of the morning bulletin to look into headless Chrome (https://moduleq.atlassian.net/browse/MQ-503). This may be something for Vasily when he is relatively unburdened. Changing designs is onerous in our current setup, because the html rendering engine we use does not support the latest CSS standards. Both Nikolay and me have been reluctant (and slow) to make non-essential changes for this reason. Morning Briefing questions Anupriya, I just had some questions about information in the morning briefing. For reference here is mine for today with numbers that correspond to my questions. On the main priority listing card, Do the numbers represent the importance of the priority, its ranking? If so, it seems to me like Microsoft should be in the number one priority based on more emails and a more recent upward trend. Do the priorities reorder themselves based on trends?Also the text below (which is unfortunately cut off here) says 'green arrows' and should probably read ‘green numbers’. On the individual priority card, there are two numbers under activity (42 emails and 57 total). The total number here does not match the email number from the first card. I assume this is a bug. What is the scope of the first number that it is less than the total? Is it the past week only? It might be good to put a qualifier in there to help not confuse people. I assume the gray band is the next upcoming meeting in that priority. Again, we might want to consider noting that so people know what it's telling them. The date and time are wrong. It appears to only display the current date and time in GMT. I assume this is another bug. a. I assume I have two entries under one email because it was somehow split, correct? I can’t seem to find an email between just me and Vasyl on for this thread though. b. Similar to new priority notifications, should my name be appearing here or should it be omitted. I know it's a lot of questions, so thanks in advance for your patience. Ryan\",\n",
    "\n",
    " \"Yes, good data points! In terms of email volume, that range seems about right for moderately busy professionals (200 per day x 20 work days per month = 4K).  It may be low for senior people. I'd expect them to be in the 5K - 10K range, and some higher.\",\n",
    "\n",
    " \"Hi Team, We bet you love SF restaurants and their great food, so we wanted to invite everyone at ModuleQ to try our dine-in app. Allset at restaurants near your office. Our mission is to help busy professionals enjoy a better lunch break. We’ve gotten great feedback from employees of local companies and built up a strong following in San Francisco, New York City, and Chicago. Everyone at ModuleQ can get a $50 credit and try Allset at their own convenience by using the codeTEAMTRY50 ($10 off first five orders). Simply pass this email along to your team. Thanks! Kate If you’re not interested, you can let me know by clicking click here. Thanks!\",\n",
    "\n",
    " \"Thanks Anupriya. If you want to work on the tasks you certainly can. Otherwise, if you have other items you want to focus on I can assign it to Nikolay. For number 5, since neither of us has strong opinions about it we'll just leave it as is.\",\n",
    "\n",
    " \"So as much as I hate to call Q an assistant we might want to. It is a common category. David you can call this now if you want to but I can take some to work through possibilities. I think we need to connect with a category that has strong search results.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first combine these mails into a single string and then explore basic processing steps related to Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned mail text\n",
    "email_string = \"\"\n",
    "for i in cleaned_mail_text:\n",
    "    email_string += str(i) + \" \"\n",
    "email_string = email_string[:-1]\n",
    "#print(email_string)\n",
    "\n",
    "# Excluding the apostrophes\n",
    "email_string = email_string.replace(\"’\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be done using nltk as follows:\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "lowcase_email_string = email_string.lower() # Convert all words to lowcase, since we will not distinguish between uppercase and lowcase\n",
    "# Let us also remove all the punctuation\n",
    "lowcase_email_nopunct_string = re.sub('['+string.punctuation+']', '', lowcase_email_string)\n",
    "words = word_tokenize(lowcase_email_nopunct_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokens = get_tokens()\n",
    "count = Counter(words)\n",
    "print(count.most_common(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We notice that most of the commonly occuring words are stopwords, which do not assist in keyphrase extraction\n",
    "# Let us exclude these stopwords and then study the frequency\n",
    "# nltk has an inbuilt set of stopwords which can be used as a reference\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing a few examples\n",
    "stopWords = list(stopwords.words('english'))\n",
    "print(\"Total stopwords recorded in the nltk library: \",len(stopWords))\n",
    "stopWords[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_email_content = []\n",
    "stopWords = set(stopwords.words('english'))\n",
    "for w in words:\n",
    "    if w not in stopWords:\n",
    "        filtered_email_content.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = Counter(filtered_email_content)\n",
    "print(count.most_common(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the tokens back to a string\n",
    "filtered_mail_content_string = \"\"\n",
    "for i in filtered_email_content:\n",
    "    filtered_mail_content_string += str(i) + \" \"\n",
    "filtered_mail_content_string = filtered_mail_content_string[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above that the word email and emails have been treated as separate words, but ideally would be considered as the same word - likewise with number and numbers. This process is called lemmatization and can be executed directly using a python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lemmatized_words_list = []\n",
    "for word in filtered_email_content:\n",
    "    lemmatized_word = wordnet_lemmatizer.lemmatize(word)\n",
    "    lemmatized_words_list.append(lemmatized_word)\n",
    "count = Counter(lemmatized_words_list)\n",
    "print(count.most_common(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on the literature, it must be noted that it is inappropriate to conclude that the most frequently occuring words are the keywords/keyphrases.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "navig\n",
      "navig\n",
      "navig\n",
      "navig\n"
     ]
    }
   ],
   "source": [
    "# Sample stemming operation using root word navigate\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "list_of_words = ['navigate','navigated','navigating','navigator']\n",
    "for word in list_of_words:\n",
    "    print(stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One observation is that the process of stemming cuts off suffixes - and if we are looking to extract key phrases, we might end up losing the phrase itself - and hence, it might not be a great tool in this case. Lemmatization is the more appropriate operation to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
